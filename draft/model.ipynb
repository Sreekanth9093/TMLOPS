{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d050cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\Lib\\site-packages\\kfp\\dsl\\component_decorator.py:126: FutureWarning: The default base_image used by the @dsl.component decorator will switch from 'python:3.9' to 'python:3.10' on Oct 1, 2025. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.10.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "# Library Imports\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Fetch the AWS keys from environment variables\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "# Check if the environment variables are set\n",
    "if aws_access_key_id and aws_secret_access_key:\n",
    "    logging.info(\"AWS Access Key and Secret Key have been retrieved successfully.\")\n",
    "    logging.info(\"AWS Access Key ID: %s\", aws_access_key_id)\n",
    "    logging.info(\"AWS Secret Access Key: %s\",\n",
    "        aws_secret_access_key[:4] + \"*\" * 16 + aws_secret_access_key[-4:])\n",
    "else:\n",
    "    raise EnvironmentError(\"AWS Access Key or Secret Key not set properly.\")\n",
    "\n",
    "@dsl.component(packages_to_install=[\"numpy\", \"pandas\", \"scikit-learn\", \"boto3\"])\n",
    "def build_model(aws_access_key_id: str, aws_secret_access_key: str):\n",
    "    # Import Libraries\n",
    "    import boto3\n",
    "    # from botocore.exceptions import ClientError\n",
    "\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    # from sklearn.metrics iawsmport mean_squared_error\n",
    "\n",
    "    bucket = \"iriscloudbt-mlapp\"\n",
    "    data_s3_path = \"data/rental_1000.csv\"\n",
    "    model_s3_path = \"model/rental_prediction_model.pkl\"\n",
    "    local_data_path = \"rental_1000.csv\"\n",
    "    local_model_path = \"rental_prediction_model.pkl\"\n",
    "\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )\n",
    "\n",
    "    # Download data from S3\n",
    "    s3_client.download_file(bucket, data_s3_path, local_data_path)\n",
    "\n",
    "    # Load the dataset\n",
    "    rentalDF = pd.read_csv(local_data_path)\n",
    "\n",
    "    # Prepare the features and labels\n",
    "    X = rentalDF[[\"rooms\", \"sqft\"]].values\n",
    "    y = rentalDF[\"price\"].values\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "    # Train the model\n",
    "    lr = LinearRegression()\n",
    "    model = lr.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model using pickle\n",
    "    with open(local_model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    # Upload the model to S3\n",
    "    s3_client.upload_file(local_model_path, bucket, model_s3_path)\n",
    "\n",
    "\n",
    "@dsl.pipeline\n",
    "def rental_prediction_pipeline():\n",
    "    build_model(aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903f45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f709709b-b634-4676-bc03-ff521b5de147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import compiler\n",
    "\n",
    "compiler.Compiler().compile(rental_prediction_pipeline, 'rental_prediction_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44354393-7ad6-4a5c-bfd9-6f78b8b9a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import kfp\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set your Kubeflow Pipelines endpoint here\n",
    "kfp_endpoint = None\n",
    "client = kfp.Client(host=kfp_endpoint)\n",
    "\n",
    "# Experiment name\n",
    "experiment_name = \"My Experiment\"\n",
    "\n",
    "# Create a new experiment\n",
    "def create_experiment(client, experiment_name):\n",
    "  experiment = client.create_experiment(name=experiment_name)\n",
    "  logging.info(f\"Created experiment: {experiment.name}\")\n",
    "  return experiment\n",
    "\n",
    "\n",
    "# List all experiments\n",
    "def list_experiments(client):\n",
    "  experiments = client.list_experiments()\n",
    "  logging.info(f\"Experiments: {experiments}\")\n",
    "  return experiments\n",
    "\n",
    "# Create a Run from a pipeline function\n",
    "def create_run_from_pipeline_func(client, pipeline_func, experiment_name, enable_caching=False):\n",
    "  run = client.create_run_from_pipeline_func(\n",
    "     pipeline_func,\n",
    "     experiment_name=experiment_name,\n",
    "     enable_caching=enable_caching\n",
    "  )\n",
    "  logging.info(\"Pipeline run initiated\")\n",
    "  return run\n",
    "\n",
    "# List all runs for a given experiment\n",
    "def list_runs(client, experiment_id):\n",
    "  runs = client.list_runs(experiment_id=experiment_id)\n",
    "  logging.info(f\"Runs: {runs}\")\n",
    "  return runs\n",
    "\n",
    "# Delete a specific run by run_id\n",
    "def delete_run(client, run_id):\n",
    "  client.delete_run(run_id)\n",
    "  logging.info(f\"Deleted run: {run_id}\")\n",
    "\n",
    "# List all runs for a given experiment and delete the first run\n",
    "def delete_previous_run(client, experiment_id):\n",
    "  runs = list_runs(client, experiment_id)\n",
    "  if runs and runs.runs:\n",
    "     run_id = runs.runs[0].run_id\n",
    "     logging.info(f\"Deleting run: {run_id}\")\n",
    "     delete_run(client, run_id)\n",
    "\n",
    "# Delete a specific experiment by experiment_id\n",
    "def delete_experiment(client, experiment_id):\n",
    "  client.delete_experiment(experiment_id)\n",
    "  logging.info(f\"Deleted experiment: {experiment_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
